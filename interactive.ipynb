{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73722374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import sklearn\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from data.dataloaders import ImagesDataset\n",
    "from models.model import SelfSupervisedLearner\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS     = 1000\n",
    "LR         = 3e-4\n",
    "IMAGE_SIZE = 96 # Change this depending on dataset\n",
    "NUM_GPUS= 0 # Change this depending on host\n",
    "NUM_WORKERS = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87eb5d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from  ./ckpt/learner_0510_v100.pt\n",
      "Train loading done\n",
      "Test loading done\n",
      "got embeddings\n"
     ]
    }
   ],
   "source": [
    "resnet = torchvision.models.resnet18(pretrained=False)\n",
    "model = SelfSupervisedLearner(\n",
    "    resnet,\n",
    "    image_size = IMAGE_SIZE,\n",
    "    hidden_layer = 'avgpool',\n",
    "    projection_size = 256,\n",
    "    projection_hidden_size = 4096,\n",
    "    moving_average_decay = 0.99,\n",
    "    lr = LR\n",
    ")\n",
    "\n",
    "    \n",
    "argv = [\"train.py\", \"--load\", \"./ckpt/learner_0510_v100.pt\"]\n",
    "model.load_state_dict(torch.load(argv[2]))\n",
    "print(\"Loaded checkpoint from \", argv[2])\n",
    "\n",
    "#TODO: for some reason labels don't exist in my wget data \n",
    "#ds = ImagesDataset(\"./dataset/test_images\", IMAGE_SIZE, train=False)\n",
    "data_transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "train_dataset = torchvision.datasets.STL10('./dataset/train_split', split='train', download=False,\n",
    "                   transform=data_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=5000, num_workers=NUM_WORKERS, shuffle=False)\n",
    "\n",
    "\n",
    "train_imgs, train_labels = next(iter(train_loader))\n",
    "print(\"Train loading done\")\n",
    "\n",
    "test_dataset = torchvision.datasets.STL10('./dataset/test_split', split='test', download=False, transform=data_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8000, num_workers=NUM_WORKERS, shuffle=False)\n",
    "test_imgs, test_labels = next(iter(test_loader))\n",
    "print(\"Test loading done\")\n",
    "\n",
    "train_projs, train_embeddings = model.learner.forward(train_imgs, return_embedding=True)\n",
    "test_projs, test_embeddings = model.learner.forward(test_imgs, return_embedding=True)\n",
    "\n",
    "print(\"got embeddings\")\n",
    "\n",
    "train_imgs = torch.flatten(train_imgs, start_dim=1)\n",
    "test_imgs = torch.flatten(test_imgs, start_dim=1)\n",
    "\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(train_imgs)\n",
    "train_imgs = scaler.transform(train_imgs).astype(np.float32)\n",
    "test_imgs = scaler.transform(test_imgs).astype(np.float32)\n",
    "\n",
    "\n",
    "pca = PCA(n_components=512)\n",
    "train_imgs_pca = pca.fit_transform(train_imgs)\n",
    "test_imgs_pca = pca.transform(test_imgs)\n",
    "\n",
    "lr_baseline = LogisticRegression(max_iter=100000)\n",
    "baseline_preds = lr_baseline.fit(train_imgs_pca, train_labels)\n",
    "\n",
    "baseline_preds = lr_baseline.predict_proba(test_imgs_pca)\n",
    "baseline_classes = lr_baseline.predict(test_imgs_pca)\n",
    "baseline_acc = sklearn.metrics.accuracy_score(test_labels, baseline_classes)\n",
    "\n",
    "lr_byol = LogisticRegression(max_iter=100000)\n",
    "lr_byol.fit(train_embeddings.detach().numpy(), train_labels)\n",
    "\n",
    "byol_preds = lr_byol.predict_proba(test_embeddings.detach().numpy())\n",
    "byol_classes = lr_byol.predict(test_embeddings.detach().numpy())\n",
    "byol_acc = sklearn.metrics.accuracy_score(test_labels, byol_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fc29f7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr baseline:  0.22225\n",
      "random embeddings:  0.402625\n",
      "lr baseline:  0.209375\n",
      "random embeddings:  0.379375\n",
      "lr baseline:  0.188625\n",
      "random embeddings:  0.329\n",
      "lr baseline:  0.220875\n",
      "random embeddings:  0.392\n",
      "lr baseline:  0.1755\n",
      "random embeddings:  0.318\n",
      "lr baseline:  0.198375\n",
      "random embeddings:  0.331\n",
      "lr baseline:  0.191375\n",
      "random embeddings:  0.3875\n",
      "lr baseline:  0.1955\n",
      "random embeddings:  0.41925\n",
      "lr baseline:  0.166625\n",
      "random embeddings:  0.369625\n",
      "lr baseline:  0.160125\n",
      "random embeddings:  0.336125\n"
     ]
    }
   ],
   "source": [
    "# lr_baseline: fitting logistic regression to random images directly\n",
    "# lr_rand: fitting logistic regression to randomly chosen embeddings from BYOL\n",
    "\n",
    "for _ in range(10):\n",
    "    random_idx = np.random.randint(0, high=train_imgs.shape[0], size = 30)\n",
    "\n",
    "    embeddings_subset = train_embeddings.detach().numpy()[random_idx]\n",
    "    train_labels_subset = train_labels[random_idx]\n",
    "\n",
    "    lr_rand = LogisticRegression(max_iter=100000)\n",
    "    lr_rand.fit(embeddings_subset, train_labels_subset)\n",
    "\n",
    "    rand_preds =lr_rand.predict(test_embeddings.detach().numpy())\n",
    "    rand_acc = sklearn.metrics.accuracy_score(test_labels, rand_preds)\n",
    "    \n",
    "    lr_baseline = LogisticRegression(max_iter=100000)\n",
    "    lr_baseline.fit(train_imgs[random_idx], train_labels_subset)\n",
    "    \n",
    "    lr_baseline_preds = lr_baseline.predict(test_imgs)\n",
    "    lr_baseline_acc = sklearn.metrics.accuracy_score(test_labels, lr_baseline_preds)\n",
    "    \n",
    "    print(\"lr baseline: \", lr_baseline_acc)\n",
    "\n",
    "    print(\"random embeddings: \", rand_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5771c599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters=10, max_iter=100000)\n",
    "km.fit(train_embeddings.detach().numpy())\n",
    "\n",
    "clusters = km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "019d399a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 901, 5: 784, 1: 644, 0: 620, 4: 557, 9: 492, 2: 384, 8: 285, 7: 232, 6: 101})\n",
      "{1: 0.7763975155279503, 4: 0.8976660682226213, 3: 0.5549389567147615, 5: 0.6377551020408164, 9: 1.016260162601626, 2: 1.3020833333333335, 6: 4.950495049504951, 0: 0.8064516129032259, 8: 1.7543859649122808, 7: 2.1551724137931036}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counts = Counter(clusters)\n",
    "total = train_embeddings.detach().numpy().shape[0]\n",
    "\n",
    "weights = {}\n",
    "uniform_prob = 0.1\n",
    "for k in counts:\n",
    "    weights[k] = uniform_prob / (counts[k] / total)\n",
    "    \n",
    "print(counts)\n",
    "print(weights)\n",
    "\n",
    "weights_full = [weights[k] for k in clusters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3a0969c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "km:  0.3675\n",
      "lr baseline acc: 0.18175\n",
      "km:  0.45175\n",
      "lr baseline acc: 0.224875\n",
      "km:  0.403625\n",
      "lr baseline acc: 0.17425\n",
      "km:  0.369875\n",
      "lr baseline acc: 0.187\n",
      "km:  0.451875\n",
      "lr baseline acc: 0.222375\n",
      "km:  0.328\n",
      "lr baseline acc: 0.193125\n",
      "km:  0.356\n",
      "lr baseline acc: 0.192375\n",
      "km:  0.36025\n",
      "lr baseline acc: 0.224625\n",
      "km:  0.417375\n",
      "lr baseline acc: 0.207375\n",
      "km:  0.406625\n",
      "lr baseline acc: 0.190375\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for _ in range(10):\n",
    "    kmeans_idx = random.choices(range(train_imgs.shape[0]), weights=weights_full, k=30)\n",
    "\n",
    "    \"\"\"\n",
    "    cluster_subset = clusters[kmeans_idx]\n",
    "    cluster_counts = Counter(cluster_subset)\n",
    "    print(cluster_subset)\n",
    "    print(cluster_counts)\n",
    "    \"\"\"\n",
    "\n",
    "    embeddings_subset = train_embeddings.detach().numpy()[kmeans_idx]\n",
    "    train_labels_subset = train_labels[kmeans_idx]\n",
    "\n",
    "    lr_km = LogisticRegression(max_iter=100000)\n",
    "    lr_km.fit(embeddings_subset, train_labels_subset)\n",
    "\n",
    "    km_preds =lr_km.predict(test_embeddings.detach().numpy())\n",
    "    km_acc = sklearn.metrics.accuracy_score(test_labels, km_preds)\n",
    "    \n",
    "    lr_baseline = LogisticRegression(max_iter=100000)\n",
    "    lr_baseline.fit(train_imgs[kmeans_idx], train_labels_subset)\n",
    "    \n",
    "    lr_baseline_preds = lr_baseline.predict(test_imgs)\n",
    "    lr_baseline_acc = sklearn.metrics.accuracy_score(test_labels, lr_baseline_preds)\n",
    "\n",
    "    print(\"km: \", km_acc)\n",
    "    print(\"lr baseline acc:\", lr_baseline_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806a15eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr baseline:  0.30075\n",
    "random embeddings:  0.655375\n",
    "lr baseline:  0.29575\n",
    "random embeddings:  0.6615"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
